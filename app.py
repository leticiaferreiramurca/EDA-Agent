import re
import warnings
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from langchain_google_genai import ChatGoogleGenerativeAI as ChatGemini
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent

warnings.filterwarnings("ignore", category=UserWarning, module="pydantic")

pattern = re.compile(r"```python\n(.*?)\n```", re.DOTALL)



def chat_with_llm(query, dataframe):
    # Update system prompt to include dataset path information
    system_prompt = f"""### PERSONA ###
Voc√™ √© um Analista de Dados S√™nior, especialista em Python, Pandas e Matplotlib. Seu objetivo √© traduzir dados brutos contidos em um DataFrame `df` em respostas claras, objetivas e acion√°veis.

### DIRETRIZES GERAIS ###
1.  **Fonte da Verdade:** Baseie 100% de suas an√°lises e conclus√µes estritamente nos dados do DataFrame. N√£o fa√ßa suposi√ß√µes externas.
2.  **Linguagem:** Responda sempre em portugu√™s do Brasil.
3.  **Incerteza:** Se uma informa√ß√£o n√£o puder ser obtida a partir dos dados, informe de maneira clara: "Com base nos dados dispon√≠veis, n√£o √© poss√≠vel fornecer essa informa√ß√£o."

### FORMATO DA RESPOSTA ###
1.  **N√ÉO EXIBA O C√ìDIGO:** Sua principal regra √© NUNCA exibir o c√≥digo Python gerado. Apresente apenas os resultados finais, como texto, tabelas e gr√°ficos.
2.  **Clareza e Objetividade:** Seja direto e use uma linguagem de neg√≥cios. Evite jarg√µes excessivamente t√©cnicos na sua explica√ß√£o.
3.  **Uso de Tabelas:** Sempre que apresentar dados com mais de uma coluna ou listas de informa√ß√µes, organize-os em tabelas formatadas em Markdown para m√°xima legibilidade.
4.  **Precis√£o Num√©rica:** Arredonde todos os valores num√©ricos (flutuantes) para 2 casas decimais.
5.  **Visualiza√ß√µes Estrat√©gicas:** Utilize gr√°ficos (Matplotlib/Seaborn) quando eles forem a melhor forma de ilustrar um ponto, especialmente para:
    - **Distribui√ß√µes:** Histogramas ou KDE.
    - **Compara√ß√µes:** Gr√°ficos de barras ou boxplots.
    - **Rela√ß√µes:** Gr√°ficos de dispers√£o (scatter plots).
6.  **Conclus√£o Expl√≠cita:** Ap√≥s apresentar os dados e/ou gr√°ficos, inclua sempre um par√°grafo conciso de conclus√£o, explicando o que os resultados significam em termos pr√°ticos.
"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": query},
    ]

    with st.spinner('Processando as respostas do Gemini...'):
        llm = ChatGemini(model=st.session_state.model_name,
                         google_api_key=st.session_state.gemini_api_key,
                         temperature=0,
                         convert_system_message_to_human=True)
        
        agent = create_pandas_dataframe_agent(
        llm=llm,
        df=dataframe,
        #prompt=messages,
        #verbose=False,
        allow_dangerous_code=True,  # Necess√°rio para execu√ß√£o de c√≥digo
        agent_executor_kwargs={"handle_parsing_errors": True})
        
        return agent


def main():
    """Main Streamlit application."""
    st.title("üìä Agente de An√°lise Explorat√≥ria de Dados")
    st.write("Fa√ßa perguntas sobre um arquivo CSV!")

    # Initialize session state variables
    if 'gemini_api_key' not in st.session_state:
        st.session_state.gemini_api_key = ''
    if 'model_name' not in st.session_state:
        st.session_state.model_name = ''

    with st.sidebar:
        st.header("Chaves de API e configura√ß√£o do Modelo")
        st.session_state.gemini_api_key = st.sidebar.text_input("Chave de API do Gemini", type="password")
   
        # Add model selection dropdown
        model_options = {
            "Gemini 2.5 Flash": "gemini-2.5-flash",
            "Gemini 2.0 Flash": "gemini-2.0-flash",
            "Gemini 1.5 Flash": "gemini-1.5-flash",
        }
        st.session_state.model_name = st.selectbox(
            "Selecione o modelo",
            options=list(model_options.keys()),
            index=0  # Default to first option
        )
        st.session_state.model_name = model_options[st.session_state.model_name]

    uploaded_file = st.file_uploader("Fa√ßa o upload de um arquivo csv", type="csv")
    
    if uploaded_file is not None:
        # Display dataset with toggle
        df = pd.read_csv(uploaded_file)
        st.write("Dataset:")
        show_full = st.checkbox("Dataset Carregado com sucesso!")
        if show_full:
            st.dataframe(df)
        else:
            st.write("Preview (primeiras 5 linhas):")
            st.dataframe(df.head())
        # Query input
        query = st.text_area("O que voc√™ gostaria de saber sobre seus dados?",
                            "Traga os valores m√°ximos de cada coluna do banco de dados.")
        
        if st.button("An√°lise"):
            if not st.session_state.gemini_api_key:
                st.error("Por favor digite suas chaves de API no campo ao lado.")
            else:
                plt.clf()
                # Pass dataset_path to chat_with_llm
                agent = chat_with_llm(query, df)
                result = agent.invoke({"input": query})
                response = result.get("output", "")

                current_fig = plt.gcf()
                if current_fig.get_axes():
                    st.pyplot(current_fig)
                    st.markdown(response)
                    # Salva com plot na mensagem
                    #ai_msg = AIMessage(content=response, additional_kwargs={"plot": current_fig})
                else:
                    st.markdown(response)
                    #ai_msg = AIMessage(content=response)
                #st.session_state.chat_history.append(ai_msg)

                    
if __name__ == "__main__":
    main()